{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T05:16:28.496355Z",
     "start_time": "2019-04-16T05:16:28.360418Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import utils.dataset as dataset\n",
    "import utils.preprocessing as preprocessing\n",
    "from utils.logger import Logger\n",
    "import lstm.model as model\n",
    "import utils.postprocessing as postprocessing\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from numpy import linalg as LA\n",
    "import numpy as np\n",
    "import logging\n",
    "import argparse\n",
    "\n",
    "\n",
    "from astropy.convolution import Gaussian1DKernel, convolve\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T06:02:06.675695Z",
     "start_time": "2019-02-28T06:02:06.658312Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T03:05:54.436270Z",
     "start_time": "2019-03-23T03:05:54.403633Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T03:05:59.837268Z",
     "start_time": "2019-03-23T03:05:59.812761Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1553310354.434949\n"
     ]
    }
   ],
   "source": [
    "print(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T03:06:26.112772Z",
     "start_time": "2019-03-23T03:06:26.055913Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1553310368.0227296\n"
     ]
    }
   ],
   "source": [
    "print(end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T03:06:08.024051Z",
     "start_time": "2019-03-23T03:06:07.999885Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T03:06:36.103032Z",
     "start_time": "2019-03-23T03:06:36.081942Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.587780714035034\n"
     ]
    }
   ],
   "source": [
    "print(end_time -start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T06:35:42.764950Z",
     "start_time": "2019-02-28T06:35:42.717765Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]predict 빈도: {-1: 4842, 1: 5158}\n"
     ]
    }
   ],
   "source": [
    "# comp_num = 45\n",
    "clf = svm.OneClassSVM(nu=0.001, kernel=\"rbf\", gamma=0.0001, verbose=True)\n",
    "clf.fit(train_x[0:20000,0:2])\n",
    "preds = clf.predict(test_x[5000:15000, 0:2]) \n",
    "unique, counts = np.unique(preds, return_counts=True)\n",
    "print('predict 빈도:', dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T06:10:27.161686Z",
     "start_time": "2019-02-28T06:10:27.112893Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]predict 빈도: {-1: 2390, 1: 7610}\n"
     ]
    }
   ],
   "source": [
    "# comp_num = 45\n",
    "clf = svm.OneClassSVM(nu=0.001, kernel=\"rbf\", gamma=0.0001, verbose=True)\n",
    "clf.fit(train_x[0:20000,0:4])\n",
    "preds = clf.predict(test_x[5000:15000, 0:4]) \n",
    "unique, counts = np.unique(preds, return_counts=True)\n",
    "print('predict 빈도:', dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T06:10:00.668563Z",
     "start_time": "2019-02-28T06:10:00.628819Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]predict 빈도: {-1: 4842, 1: 5158}\n"
     ]
    }
   ],
   "source": [
    "# comp_num = 2\n",
    "clf = svm.OneClassSVM(nu=0.001, kernel=\"rbf\", gamma=0.0001, verbose=True)\n",
    "clf.fit(train_x[0:20000,:])\n",
    "preds = clf.predict(test_x[5000:15000, :]) \n",
    "unique, counts = np.unique(preds, return_counts=True)\n",
    "print('predict 빈도:', dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-10T05:04:33.683604Z",
     "start_time": "2019-03-10T05:04:33.654325Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class ENCODER(nn.Module):\n",
    "\n",
    "    def __init__(self,args):\n",
    "        super(ENCODER, self).__init__()\n",
    "        self.args = args\n",
    "        self.drop = nn.Dropout(args['dropout'])\n",
    "        self.linear = nn.Linear(args['hidden_size'], args['data_dim'])\n",
    "\n",
    "        if args['cell_type'] in ['LSTM', 'GRU']:\n",
    "            self.rnn = getattr(nn, args['cell_type'])(args['rnn_inp_size'], args['hidden_size'], args['nlayers'], dropout=args['dropout'])\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.linear.weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear.bias.data.fill_(0)\n",
    "\n",
    "    def forward(self, input, hidden, return_hiddens=False, noise=False):\n",
    "        output, hidden = self.rnn(input, hidden)\n",
    "        output = self.linear(output.contiguous().view(-1,self.args['hidden_size']))\n",
    "        output = output.contiguous().view(input.size()[0], -1, self.args['rnn_inp_size'])\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters()).data ############# 이게 무엇\n",
    "        if self.args['cell_type'] == 'LSTM':\n",
    "            return (Variable(weight.new(self.args['nlayers'], bsz, self.args['hidden_size']).zero_()),\n",
    "                    Variable(weight.new(self.args['nlayers'], bsz, self.args['hidden_size']).zero_()))\n",
    "\n",
    "    def repackage_hidden(self,h):\n",
    "        \"\"\"Wraps hidden states in new Variables, to detach them from their history.\"\"\"\n",
    "        if type(h) == tuple:\n",
    "            return tuple(self.repackage_hidden(v) for v in h)\n",
    "        else:\n",
    "            return Variable(h.data)\n",
    "\n",
    "    def extract_hidden(self, hidden):\n",
    "        if self.args['cell_type'] == 'LSTM':\n",
    "            return hidden[0][-1].data.cpu()  # hidden state last layer (hidden[1] is cell state)\n",
    "        else:\n",
    "            return hidden[-1].data.cpu()  # last layer\n",
    "\n",
    "        \n",
    "class DECODER(nn.Module):\n",
    "\n",
    "    def __init__(self,args):\n",
    "        super(DECODER, self).__init__()\n",
    "        self.args = args\n",
    "        self.drop = nn.Dropout(args['dropout'])\n",
    "        self.linear = nn.Linear(args['hidden_size'], args['data_dim'])\n",
    "\n",
    "        if args['cell_type'] in ['LSTM', 'GRU']:\n",
    "            self.rnn = getattr(nn, args['cell_type'])(args['rnn_inp_size'], args['hidden_size'], args['nlayers'], dropout=args['dropout'])\n",
    "\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.linear.weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear.bias.data.fill_(0)\n",
    "        \n",
    "    def forward(self, input, hidden, return_hiddens=False, noise=False):\n",
    "        \n",
    "        output, hidden = self.rnn(input, hidden)\n",
    "        output = self.linear(output.contiguous().view(-1,self.args['hidden_size']))\n",
    "        output = output.contiguous().view(input.size()[0], -1, self.args['rnn_inp_size'])\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters()).data ############# 이게 무엇\n",
    "        if self.args['cell_type'] == 'LSTM':\n",
    "            return (Variable(weight.new(self.args['nlayers'], bsz, self.args['hidden_size']).zero_()),\n",
    "                    Variable(weight.new(self.args['nlayers'], bsz, self.args['hidden_size']).zero_()))\n",
    "\n",
    "    def repackage_hidden(self,h):\n",
    "        \"\"\"Wraps hidden states in new Variables, to detach them from their history.\"\"\"\n",
    "        if type(h) == tuple:\n",
    "            return tuple(self.repackage_hidden(v) for v in h)\n",
    "        else:\n",
    "            return Variable(h.data)\n",
    "\n",
    "    def extract_hidden(self, hidden):\n",
    "        if self.args['cell_type'] == 'LSTM':\n",
    "            return hidden[0][-1].data.cpu()  # hidden state last layer (hidden[1] is cell state)\n",
    "        else:\n",
    "            return hidden[-1].data.cpu()  # last layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T05:04:10.179939Z",
     "start_time": "2019-04-16T05:04:10.142707Z"
    }
   },
   "outputs": [],
   "source": [
    "class Solver():\n",
    "    def __init__(self, args):\n",
    "        \n",
    "        torch.manual_seed(777)\n",
    "        torch.cuda.manual_seed_all(777)\n",
    "        np.random.seed(777)\n",
    "        \n",
    "        self.attack_list = pd.read_csv(args.attack_list_path, error_bad_lines=False, sep='\\t')\n",
    "\n",
    "        self.tf_log = args.tf_log\n",
    "        \n",
    "        train_x, test_x, test_y = dataset.lstm_dataset(train_path = args.train_path, test_path = args.test_path)\n",
    "        \n",
    "        train_x_batchfy = preprocessing.batchify(args, train_x, args.batch_size)\n",
    "        test_x_batchfy = preprocessing.batchify(args, test_x, args.batch_size)\n",
    "        generate_batchfy = preprocessing.batchify(args, test_x, 1)\n",
    "        train_generate_batchfy = preprocessing.batchify(args, train_x, 1)\n",
    "        \n",
    "        self.train_x_batchfy = train_x_batchfy[:,:,args.selected_dim]\n",
    "        self.test_x_batchfy = test_x_batchfy[:,:,args.selected_dim]\n",
    "        self.generate_batchfy = generate_batchfy[:,:,args.selected_dim]\n",
    "        self.train_generate_batchfy = train_generate_batchfy[:,:,args.selected_dim]\n",
    "        self.test_y = test_y\n",
    "        \n",
    "\n",
    "        self.args = args\n",
    "        self.encoder = model.ENCODER(self.args)\n",
    "        self.encoder.cuda()\n",
    "\n",
    "        self.decoder = model.DECODER(self.args)\n",
    "        self.decoder.cuda()\n",
    "\n",
    "        self.optim_enc   = torch.optim.Adam(self.encoder.parameters(), self.args.lr)\n",
    "        self.optim_dec   = torch.optim.Adam(self.decoder.parameters(), self.args.lr)\n",
    "\n",
    "        self.loss_fn = nn.MSELoss()    \n",
    "    \n",
    "        self.logger = Logger('./tf_logs')\n",
    "    \n",
    "        self.base_dir = Path('model_save')\n",
    "        self.base_dir.mkdir(parents=True,exist_ok=True)      \n",
    "        \n",
    "#         self.evaluate = args.evaluate\n",
    "    \n",
    "#     def make_dir_name(self, args):\n",
    "#         return 'modelName:'+args.model_name+'__cellType:'+args.cell_type \\\n",
    "#                 + '__hidSize:' + str(args.hidden_size) + '__dropout:' + str(args.dropout)\n",
    "\n",
    "\n",
    "\n",
    "#TODO 로그 정리\n",
    "#         self.log = logging.getLogger('LSTM_log')\n",
    "#         self.log.setLevel(logging.DEBUG)\n",
    "\n",
    "#         formatter = logging.Formatter('%(asctime)s > %(message)s')\n",
    "\n",
    "#         fileHandler = logging.FileHandler('./log/logger.txt')\n",
    "\n",
    "#         fileHandler.setFormatter(formatter)\n",
    "#         self.log.addHandler(fileHandler)\n",
    "        \n",
    "#         self.log.critical(\"Selected dim : \" + str(args.selected_dim))\n",
    "        log.critical(\"\\n\")\n",
    "        log.critical(\"Selected dim : \" + str(args.selected_dim))\n",
    "\n",
    "\n",
    "\n",
    "    def load(self, path):\n",
    "        try:\n",
    "#             checkpoint = torch.load(Path(self.base_dir, str(args.selected_dim)))\n",
    "#             checkpoint = checkpoint.with_suffix('.pth')\n",
    "#             start_epoch = checkpoint['epoch\n",
    "#             self.encoder.load_state_dict(checkpoint['state_dict_enc)\n",
    "#             self.optim_enc.load_state_dict((checkpoint['optimizer_enc))\n",
    "#             self.decoder.load_state_dict(checkpoint['state_dict_dec)\n",
    "#             self.optim_dec.load_state_dict((checkpoint['optimizer_dec))            \n",
    "#             del checkpoint\n",
    "            print(\"=> loaded checkpoint\")\n",
    "        except:\n",
    "            print(\"=> Not exist checkpoint\")\n",
    "            pass        \n",
    "\n",
    "    def fit(self, load):\n",
    "        total_loss = 0\n",
    "        max_f1 = 0\n",
    "        total_length = self.train_x_batchfy.size(0) - 1\n",
    "        start_time = time.time()\n",
    "        \n",
    "        \n",
    "                                          \n",
    "        for epoch in range(0, self.args.epoch):\n",
    "\n",
    "            self.encoder.train()\n",
    "            self.decoder.train()\n",
    "                \n",
    "            hidden_enc = self.encoder.init_hidden(self.args.batch_size)\n",
    "\n",
    "            for batch, i in enumerate(range(0, self.train_x_batchfy.size(0) - 1, self.args.seq_length)):\n",
    "                outSeq = []\n",
    "                inputSeq, targetSeq = preprocessing.get_batch(self.args, self.train_x_batchfy, i)\n",
    "\n",
    "                if args.seq_length != targetSeq.size()[0] :\n",
    "                    continue\n",
    "                hidden_enc = self.encoder.repackage_hidden(hidden_enc)\n",
    "                self.optim_enc.zero_grad()\n",
    "                self.optim_dec.zero_grad()\n",
    "                \n",
    "                Outputseq_enc, hidden_enc = self.encoder.forward(inputSeq, hidden_enc, return_hiddens=True)\n",
    "                deccoder_input = Variable(torch.zeros(Outputseq_enc.size())).cuda()\n",
    "                \n",
    "                deccoder_input[0,:,:] = Outputseq_enc[-1,:,:] # inputSeq[-1,:,:]\n",
    "                deccoder_input[1:,:,:] = targetSeq[:-1,:,:]\n",
    "                \n",
    "                loss_enc = self.loss_fn(Outputseq_enc[-1,:,:].view(self.args.batch_size, -1), targetSeq[0,:,:].contiguous().view(self.args.batch_size, -1))\n",
    "                loss_enc.backward(retain_graph=True)\n",
    "                \n",
    "                \n",
    "                encoder_norm = sum(p.grad.data.abs().sum() for p in self.encoder.parameters())\n",
    "                \n",
    "                torch.nn.utils.clip_grad_norm_(self.encoder.parameters(), self.args.clip)\n",
    "                \n",
    "                self.optim_enc.step()     \n",
    "                \n",
    "                Outputseq_enc, hidden_enc = self.decoder.forward(deccoder_input, hidden_enc, return_hiddens=True)\n",
    "                loss_dec = self.loss_fn(Outputseq_enc.view(args.batch_size, -1), targetSeq.contiguous().view(args.batch_size, -1))   \n",
    "                loss_dec.backward()\n",
    "                \n",
    "                edecoder_norm = sum(p.grad.data.abs().sum() for p in self.decoder.parameters())\n",
    "                \n",
    "                \n",
    "                torch.nn.utils.clip_grad_norm_(self.decoder.parameters(), self.args.clip)\n",
    "                self.optim_dec.step()\n",
    "                \n",
    "                \n",
    "                \n",
    "                total_loss += loss_enc.item() + loss_dec.item()        \n",
    "\n",
    "                if batch % 30 == 0 and self.tf_log == True :\n",
    "                    print(encoder_norm)\n",
    "                    print(decoder_norm)\n",
    "                    # 1. Log scalar values (scalar summary)\n",
    "                    info = { 'enc_loss': loss_enc.item(), 'dec_loss' : loss_dec.item() }\n",
    "\n",
    "                    for tag, value in info.items():\n",
    "                        self.logger.scalar_summary(tag, value, epoch*total_length + i +1)\n",
    "\n",
    "                    # 2. Log values and gradients of the parameters (histogram summary)\n",
    "                    for tag, value in self.encoder.named_parameters():\n",
    "                        tag = tag.replace('.', '/')\n",
    "                        self.logger.histo_summary(tag, value.data.cpu().numpy(), epoch*total_length + i +1)\n",
    "                        \n",
    "                    for tag, value in self.decoder.named_parameters():\n",
    "                        tag = tag.replace('.', '/')\n",
    "                        self.logger.histo_summary(tag, value.data.cpu().numpy(), epoch*total_length + i +1)\n",
    "            \n",
    "            total_loss = 0    \n",
    "            if len(self.args.selected_dim) == 1:\n",
    "                self.anomal_score = postprocessing.get_anomalscore_encdec_1dim(base_model = self,  \\\n",
    "                                                                 generate_batchfy = self.generate_batchfy, length = 449916,args = self.args)\n",
    "            else:    \n",
    "                self.anomal_score = postprocessing.get_anomalscore_encdec(base_model = self,  \\\n",
    "                                                                 generate_batchfy = self.generate_batchfy, length = 449916,args = self.args)\n",
    "\n",
    "            self.anomal_score = LA.norm(self.anomal_score, axis=1)\n",
    "    #TODO conv 설정\n",
    "            max_conv, max_pre, max_recall, max_f1_tp, max_zerolist, find_attack_list = postprocessing.evaluate_conv(self.anomal_score, self.test_y, self.attack_list, 400)\n",
    "    \n",
    "          \n",
    "            if max_f1_tp > max_f1:\n",
    "                end_time = time.time()\n",
    "                \n",
    "#                 print(\"epoch[{}]\\t conv[{}]\\t precision[{}]\\t recall[{}]\\t f1[{}]\\t findnum[{}]\\t time[{}]\".format(epoch, max_conv, max_pre, max_recall, max_f1_tp,36 - max_zerolist, end_time - start_time))\n",
    "                \n",
    "                #TODP self로 바꿔야함\n",
    "                log.info(\"epoch[{}]\\t conv[{}]\\t precision[{}]\\t recall[{}]\\t f1[{}]\\t findnum[{}]\\t time[{}]\".format(epoch, max_conv, max_pre, max_recall, max_f1_tp,36 - max_zerolist, end_time - start_time))\n",
    "                log.info(find_attack_list)\n",
    "                \n",
    "                self.model_dictionary = {'epoch': epoch,\n",
    "                        'state_dict_enc': self.encoder.state_dict(),\n",
    "                        'optimizer_enc': self.optim_enc.state_dict(),\n",
    "                        'state_dict_dec': self.decoder.state_dict(),\n",
    "                        'optimizer_dec': self.optim_dec.state_dict(),\n",
    "                        'args':args,\n",
    "                        'loss':total_loss,\n",
    "                        'anomal_score' : self.anomal_score ,\n",
    "                         'conv' : max_conv,\n",
    "                        'f1' : max_f1_tp,\n",
    "                         'find_attack_list': find_attack_list                \n",
    "                        }\n",
    "                self.save_checkpoint(self.args, self.model_dictionary)\n",
    "                max_f1 = max_f1_tp\n",
    "                                    \n",
    "            \n",
    "            \n",
    "            \n",
    " \n",
    "    def save_checkpoint(self, args, state):\n",
    "        checkpoint = Path(self.base_dir, str(args.selected_dim))\n",
    "        checkpoint = checkpoint.with_suffix('.pth')\n",
    "        torch.save(state, checkpoint)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T05:04:19.793839Z",
     "start_time": "2019-04-16T05:04:19.768954Z"
    }
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument(\"--cuda\", default=True, action=\"store_true\")\n",
    "parser.add_argument(\"--tf_log\", default=False, action=\"store_true\")\n",
    "parser.add_argument(\"--model_name\", type=str, default=\"enc_dec\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=256)\n",
    "parser.add_argument(\"--clip\", type=int, default=1)\n",
    "\n",
    "parser.add_argument(\"--train_path\", type=str, default=\"../../DATA/SWaT/SWaT_Physical/SWaT_Dataset_Normal_v0.csv\")\n",
    "parser.add_argument(\"--test_path\", type=str, default=\"../../DATA/SWaT/SWaT_Physical/SWaT_Dataset_Attack_v0.csv\")\n",
    "parser.add_argument(\"--attack_list_path\", type=str, default='../../DATA/SWaT/SWaT_Physical/attack_list.csv')\n",
    "\n",
    "parser.add_argument(\"--dropout\", type=float, default=0.5)\n",
    "parser.add_argument(\"--hidden_size\", type=int, default=128)\n",
    "parser.add_argument(\"--nlayers\", type=int, default=2)\n",
    "parser.add_argument(\"--lr\", type=float, default=0.0001)\n",
    "\n",
    "parser.add_argument(\"--cell_type\", type=str, default=\"LSTM\")\n",
    "parser.add_argument(\"--epoch\", type=int, default=10)\n",
    "parser.add_argument(\"--seq_length\", type=int, default=2)\n",
    "parser.add_argument('--selected_dim', nargs='+', type=int, default=[36, 38, 28, 40])\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T05:26:44.325766Z",
     "start_time": "2019-04-16T05:16:32.680236Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7d3a5093431d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-7ea4872b66ae>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, load)\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manomal_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpostprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_anomalscore_encdec_1dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m                                                                   \u001b[0mgenerate_batchfy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_batchfy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m449916\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manomal_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpostprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_anomalscore_encdec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m                                                                   \u001b[0mgenerate_batchfy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_batchfy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m449916\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manomal_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manomal_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/swat_anomal/utils/postprocessing.py\u001b[0m in \u001b[0;36mget_anomalscore_encdec\u001b[0;34m(base_model, generate_batchfy, length, args)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mendPoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mOutputseq_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_enc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_batchfy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mdeccoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOutputseq_enc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mdeccoder_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOutputseq_enc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/swat_anomal/lstm/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden, return_hiddens, noise)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_hiddens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselected_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/latest_3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/latest_3.6/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mhas_flat_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_ptrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_flat_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mfirst_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/latest_3.6/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mhas_flat_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_ptrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_flat_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mfirst_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "args.selected_dim = [0, 40]\n",
    "args.hidden_size = 128\n",
    "solver = Solver(args = args)\n",
    "solver.fit(load = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.selected_dim = [0, 40]\n",
    "solver = Solver(args = args)\n",
    "solver.fit(load = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T04:47:45.123777Z",
     "start_time": "2019-04-16T04:47:45.083113Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin\n"
     ]
    }
   ],
   "source": [
    "candi_1 = [0, 1, 2, 3, 4,36,37,38,39,40]\n",
    "candi_2 = [0, 1, 2, 3, 4, 5]\n",
    "candi_3 = [35, 36,37,38,39,40]\n",
    "candi_4 = [17,18,19,20,21,22]\n",
    "\n",
    "log = logging.getLogger('LSTM_log')\n",
    "log.setLevel(logging.DEBUG)\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s > %(message)s')\n",
    "\n",
    "fileHandler = logging.FileHandler('./log/logger.txt')\n",
    "\n",
    "fileHandler.setFormatter(formatter)\n",
    "log.addHandler(fileHandler)\n",
    "# arg_list = []    \n",
    "# for i in range(len(candi_1)):\n",
    "#     arg_list.append(candi_1[i])  \n",
    "#     args.selected_dim = arg_list\n",
    "#     solver = Solver(args = args)\n",
    "#     solver.fit(load = False)\n",
    "#     arg_list = []   \n",
    "    \n",
    "arg_list = []    \n",
    "# for i in range(0,4):\n",
    "# #     for k in range(0,4):\n",
    "#     for p in range(0,4):\n",
    "#         arg_list.append(candi_2[i])\n",
    "#         arg_list.append(candi_2[i+1])\n",
    "#         arg_list.append(candi_2[i+2])\n",
    "#         arg_list.append(candi_3[k])\n",
    "#         arg_list.append( candi_3[k+1])\n",
    "#         arg_list.append( candi_3[k+2])\n",
    "#         arg_list.append(candi_4[p])\n",
    "#         arg_list.append(candi_4[p+1])\n",
    "#         arg_list.append(candi_4[p+2])\n",
    "#         args.selected_dim = arg_list\n",
    "#         solver = Solver(args = args)\n",
    "#         solver.fit(load = False)  \n",
    "#         arg_list = []   \n",
    "print(\"fin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T08:14:31.427585Z",
     "start_time": "2019-03-26T07:26:10.250661Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In train : {'Normal': 496800}\n",
      "In test : {'Attack': 54621, 'Normal': 395298}\n",
      "data length is 51\n"
     ]
    }
   ],
   "source": [
    "i = 3\n",
    "k =3 \n",
    "p= 3\n",
    "arg_list = [] \n",
    "arg_list.append(candi_2[i])\n",
    "arg_list.append(candi_2[i+1])\n",
    "arg_list.append(candi_2[i+2])\n",
    "arg_list.append(candi_3[k])\n",
    "arg_list.append( candi_3[k+1])\n",
    "arg_list.append( candi_3[k+2])\n",
    "arg_list.append(candi_4[p])\n",
    "arg_list.append(candi_4[p+1])\n",
    "arg_list.append(candi_4[p+2])\n",
    "args.selected_dim = arg_list\n",
    "solver = Solver(args = args)\n",
    "solver.fit(load = False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T05:23:00.327595Z",
     "start_time": "2019-03-23T04:44:21.313276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In train : {'Normal': 496800}\n",
      "In test : {'Attack': 54621, 'Normal': 395298}\n",
      "data length is 51\n",
      "epoch[0]\t conv[190]\t precision[0.4968557953408604]\t recall[0.6364768129474012]\t f1[0.5580659919255805]\t findnum[25]\t time[232.773029088974]\n",
      "epoch[2]\t conv[190]\t precision[0.6496848335767546]\t recall[0.6189377711869062]\t f1[0.6339387006947506]\t findnum[23]\t time[694.000387430191]\n",
      "epoch[4]\t conv[180]\t precision[0.6844791962079164]\t recall[0.6186265355815529]\t f1[0.6498889284237452]\t findnum[21]\t time[1156.1872382164001]\n",
      "epoch[5]\t conv[190]\t precision[0.7115196842214605]\t recall[0.6270298969260907]\t f1[0.6666082759157616]\t findnum[21]\t time[1386.4979054927826]\n",
      "epoch[7]\t conv[190]\t precision[0.8244008427706083]\t recall[0.6877025319931894]\t f1[0.749872735439437]\t findnum[21]\t time[1848.0769476890564]\n",
      "epoch[8]\t conv[140]\t precision[0.7867742238063972]\t recall[0.7678182384064737]\t f1[0.7771806608231566]\t findnum[21]\t time[2078.4752616882324]\n"
     ]
    }
   ],
   "source": [
    "whole = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n",
    "args.selected_dim = whole\n",
    "solver = Solver(args = args)\n",
    "solver.fit(load = False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
